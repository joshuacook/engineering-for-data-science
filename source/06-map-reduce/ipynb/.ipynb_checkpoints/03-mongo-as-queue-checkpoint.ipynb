{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mongo As Queue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from redis import Redis\n",
    "\n",
    "redis_connection = Redis(host='this_redis')\n",
    "mongo_client = pymongo.MongoClient('this_mongo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admin', 'local']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongo_client.database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "twentyktweets = pd.read_pickle('../data/twentyktweets.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7f9da5486088>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongo_client.twitter.tweets.insert_many(twentyktweets.to_dict('records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel MapReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redis import Redis \n",
    "from rq import Queue\n",
    "from lib.worker import remove_punctuation, mapper, reducer, toggle_hold, check_hold\n",
    "import time\n",
    "redis_connection = Redis('this_redis')\n",
    "job_queue = Queue(connection=redis_connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our previous implementation of the `word_count` function.\n",
    "\n",
    "    def word_count(documents, redis_connection, word_list='word_list'):\n",
    "\n",
    "        counts = []\n",
    "\n",
    "        for document in documents:\n",
    "            mapper(document, redis_connection, word_list)\n",
    "\n",
    "        word = redis_connection.spop(word_list)\n",
    "        while word:\n",
    "            word = word.decode()\n",
    "            count = reducer(word, redis_connection)\n",
    "            counts.append((word, count))\n",
    "            word = redis_connection.spop(word_list)\n",
    "\n",
    "        return counts\n",
    "        \n",
    "There are two candidates for parallelization in this function:\n",
    "\n",
    "1. the `for` loop can be parallelized as tokenization of one document is completely independent of the tokenization of another.\n",
    "1. the `while` loop can be parallelized as the counting of tokens for one word is completely independent of the counting of another.\n",
    "\n",
    "There was one tricky aspect to this parallelization, however. We cannot work on the word counts until all of the tokenization is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(documents, word_list='word_list', count_list='count_list'):\n",
    "    \n",
    "    for document in documents:\n",
    "        job = job_queue.enqueue(mapper, document, 'word_list')   \n",
    "        \n",
    "    word = redis_connection.spop('word_list')x\n",
    "    job_queue.enqueue(reducer, word, 'count_list', depends_on=job)\n",
    "    \n",
    "    while word:\n",
    "        word = word.decode()\n",
    "        job_queue.enqueue(reducer, word, 'count_list')\n",
    "        word = redis_connection.spop('word_list')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finished'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_documents(documents):\n",
    "    for document in documents:\n",
    "        job = job_queue.enqueue(mapper, document, 'word_list')\n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queued'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = map_documents(documents)\n",
    "job.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finished'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_words():\n",
    "\n",
    "    word = redis_connection.spop('word_list')\n",
    "    while word:\n",
    "        word = word.decode()\n",
    "        job = job_queue.enqueue(reducer, word, 'count_list')\n",
    "        word = redis_connection.spop('word_list')\n",
    "    \n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = reduce_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queued'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_counts():\n",
    "    \n",
    "    counts = []\n",
    "    count = redis_connection.lpop('count_list')\n",
    "    while count:\n",
    "        counts.append(count)\n",
    "        count = redis_connection.lpop('count_list')\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b\"('information', 2)\",\n",
       " b\"('selects', 1)\",\n",
       " b\"('The', 6)\",\n",
       " b\"('a', 8)\",\n",
       " b\"('variables', 3)\",\n",
       " b\"('it', 1)\",\n",
       " b\"('tool', 1)\",\n",
       " b\"('be', 2)\",\n",
       " b\"('presents', 1)\",\n",
       " b\"('clear', 1)\",\n",
       " b\"('This', 2)\",\n",
       " b\"('model', 3)\",\n",
       " b\"('testing', 2)\",\n",
       " b\"('variable', 1)\",\n",
       " b\"('eliminate', 1)\",\n",
       " b\"('most', 1)\",\n",
       " b\"('solve', 1)\",\n",
       " b\"('DRP', 2)\",\n",
       " b\"('of', 5)\",\n",
       " b\"('experimental', 1)\",\n",
       " b\"('allows', 1)\",\n",
       " b\"('techniques', 1)\",\n",
       " b\"('to', 9)\",\n",
       " b\"('kernel', 3)\",\n",
       " b\"('kernelPCA', 2)\",\n",
       " b\"('more', 1)\",\n",
       " b\"('improving', 1)\",\n",
       " b\"('market', 1)\",\n",
       " b\"('In', 1)\",\n",
       " b\"('this', 1)\",\n",
       " b\"('However', 1)\",\n",
       " b\"('is', 5)\",\n",
       " b\"('capture', 1)\",\n",
       " b\"('PCA', 3)\",\n",
       " b\"('sliding', 1)\",\n",
       " b\"('these', 1)\",\n",
       " b\"('than', 1)\",\n",
       " b\"('proposed', 1)\",\n",
       " b\"('research', 1)\",\n",
       " b\"('dimension', 1)\",\n",
       " b\"('profits', 1)\",\n",
       " b\"('applied', 2)\",\n",
       " b\"('use', 2)\",\n",
       " b\"('but', 1)\",\n",
       " b\"('approach', 1)\",\n",
       " b\"('strategies', 1)\",\n",
       " b\"('application', 2)\",\n",
       " b\"('very', 1)\",\n",
       " b\"('can', 1)\",\n",
       " b\"('formed', 1)\",\n",
       " b\"('transformation', 1)\",\n",
       " b\"('small', 1)\",\n",
       " b\"('the', 5)\",\n",
       " b\"('method', 5)\",\n",
       " b\"('realworld', 1)\",\n",
       " b\"('set', 1)\",\n",
       " b\"('fail', 1)\",\n",
       " b\"('analysis', 2)\",\n",
       " b\"('we', 1)\",\n",
       " b\"('other', 1)\",\n",
       " b\"('in', 2)\",\n",
       " b\"('characteristics', 1)\",\n",
       " b\"('extract', 1)\",\n",
       " b\"('been', 2)\",\n",
       " b\"('still', 1)\",\n",
       " b\"('America', 1)\",\n",
       " b\"('problems', 2)\",\n",
       " b\"('for', 2)\",\n",
       " b\"('implemented', 1)\",\n",
       " b\"('features', 4)\",\n",
       " b\"('indicate', 1)\",\n",
       " b\"('technical', 1)\",\n",
       " b\"('indices', 1)\",\n",
       " b\"('kernelbased', 2)\",\n",
       " b\"('reduction', 1)\",\n",
       " b\"('on', 1)\",\n",
       " b\"('that', 4)\",\n",
       " b\"('smaller', 1)\",\n",
       " b\"('practical', 1)\",\n",
       " b\"('another', 1)\",\n",
       " b\"('nonlinear', 1)\",\n",
       " b\"('window', 1)\",\n",
       " b\"('using', 1)\",\n",
       " b\"('reflect', 1)\",\n",
       " b\"('various', 1)\",\n",
       " b\"('extraction', 3)\",\n",
       " b\"('data', 2)\",\n",
       " b\"('trading', 3)\",\n",
       " b\"('stock', 5)\",\n",
       " b\"('only', 1)\",\n",
       " b\"('collinearity', 1)\",\n",
       " b\"('halfyear', 1)\",\n",
       " b\"('dimensionality', 1)\",\n",
       " b\"('transform', 1)\",\n",
       " b\"('methods', 3)\",\n",
       " b\"('from', 2)\",\n",
       " b\"('selection', 1)\",\n",
       " b\"('component', 2)\",\n",
       " b\"('results', 1)\",\n",
       " b\"('environment', 1)\",\n",
       " b\"('performance', 1)\",\n",
       " b\"('stocks', 1)\",\n",
       " b\"('generates', 1)\",\n",
       " b\"('feature', 4)\",\n",
       " b\"('possible', 1)\",\n",
       " b\"('both', 2)\",\n",
       " b\"('has', 3)\",\n",
       " b\"('and', 5)\",\n",
       " b\"('realtime', 1)\",\n",
       " b\"('critical', 2)\",\n",
       " b\"('noisy', 1)\",\n",
       " b\"('1year', 1)\",\n",
       " b\"('which', 2)\",\n",
       " b\"('paper', 1)\",\n",
       " b\"('principal', 2)\",\n",
       " b\"('one', 1)\",\n",
       " b\"('show', 1)\",\n",
       " b\"('collinear', 1)\",\n",
       " b\"('mapping', 3)\",\n",
       " b\"('known', 2)\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
