{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Compute Cloud "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch a New AWS EC2 Instance\n",
    "\n",
    "#### AWS EC2 `t2.micro`\n",
    "\n",
    "AWS EC2 virtual machines are available to meet a host of different applications and purposes. The `m` series and the `t` series are considered in general purpose and are adequate for our needs. Additionally, the `t2.micro` from the `t` series is considered a  machine \"free-tier\" and can be run for free under certain circumstances. We will use this type of machine as often as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Launch Instance\n",
    "\n",
    "To create a new instance, start from the EC2 control panel and click the Launch Instance button (fig. \\ref{fig:launch_instance})."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Begin the launch process for a new instance](doc/img/ch-01-launch_instance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Choose an Amazon Machine Image (AMI)\n",
    "\n",
    "The launching of a new instance is a multi-step process that walks the user through all configurations necessary. The **first tab** is “Choose AMI.” An AMI is an Amazon Machine Image\\footnote{http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html}. and contains the software you will need to run your sandbox machine. I recommend choosing the latest stable Ubuntu Server release that is free-tier eligible. At the time of writing, this was ami-efd0428f, Ubuntu Server 16.04 LTS (HVM), SSD Volume Type (fig. \\ref{fig:latest_ubuntu})."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Choose the latest stable Ubuntu Server release as AMI](doc/img/ch-01-latest_ubuntu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Choose Instance Type\n",
    "The **second tab** is “Choose Instance Type.” In practice, I have found that the free tier, `t2.micro`  (fig. \\ref{fig:choose_type}), is sufficient for many applications. Furthermore, the instance type may always be changed later should the need present itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Choose `t2.micro` for Instance Type](doc/img/ch-01-choose_type.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Configure Instance Details\n",
    "\n",
    "The **third tab**, “Configure Instance,” can be safely ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Add Storage\n",
    "\n",
    "The **fourth tab** is “Add Storage.” This option is also specific to intended usage. It should be noted that Jupyter Docker images can take up more than 5GB of disk\n",
    "space in the local image cache. For this reason, it is recommended to raise the value from the default 8GB to 30GB. Furthermore, as noted on this tab:\n",
    "\n",
    "> Free tier eligible customers can get up to 30 GB of EBS General Purpose (SSD) or Magnetic storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Add Tags\n",
    "\n",
    "The fifth tab, “Add Tags,” can be safely ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Configure Security Group\n",
    "\n",
    "The sixth tab, “Configure Security Group,” is critical for the proper functioning of your systems. By default this tab will be set up to \"Create a **new** security group\". This will not work for us! Ultimately, we will be accessing our system via a web browser which we require at a minimum that port 80 is open. We recommend simply using the default group which will open our system on all ports. If greater security is required for your specific application a more restrictive security group may be defined and used.\n",
    "\n",
    "Select the \"default\" security group (fig. \\ref{fig:default_security_group})."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Choose the latest stable Ubuntu Server release as AMI](doc/img/ch-01-default_security_group.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\square$ **Note:** You may receive a Warning stating, \"Rules with source of 0.0.0.0/0 allow all IP addresses to access your instance. We recommend setting security group rules to allow access from known IP addresses only.\" This is expected and is okay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Review Instance Launch\n",
    "\n",
    "Finally, click “Review and Launch.” Here, you see the specific configuration of the EC2 instance you will be creating. Verify that you are creating a `t2.micro` (fig. \\ref{fig:review_and_launch}, #2)running the latest free tier-eligible version of Ubuntu Server (fig. \\ref{fig:review_and_launch}, #1)and that it is available to all traffic (fig. \\ref{fig:review_and_launch}, #3), and then click the Launch button (fig. \\ref{fig:review_and_launch}, #4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Review and launch the new instance](doc/img/ch-01-review_and_launch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add an SSH Key\n",
    "\n",
    "In a final confirmation step, you will see a modal titled “Select an existing key pair or create a new key pair.” Select the key pair you previously created. Check the box acknowledging access to that key pair and launch the instance (fig. \\ref{fig:add_key_pair})."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Add a key pair to the instance](doc/img/ch-01-add_key_pair.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\square$ **Note:** If this step is not done correctly, that is, if the correct key pair is not added to the launching instance, the instance will need to be terminated and a new instance will need to be launched. There is now way to add a key pair to a running instance.\n",
    "\n",
    "You should see a notification that the instance is now running. Click the View Instances tab in the lower right corner to be taken to the EC2 Dashboard Instances pane, where you should see your new instance running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examing the Newly Launched Instance\n",
    "\n",
    "Make note of the IP address of the new instance (fig. \\ref{fig:new_ip})."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Add a key pair to the instance](doc/img/ch-01-new_ip.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Git & Github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armed with our new ssh key, we will add the public key to Github so that we can use the key to access our github account. \n",
    "\n",
    "1. copy the public key \n",
    "1. choose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we will do is create a new local `git` repository and a remote Github repository. The local repository is where we will do all of our work. We will use the remote Github repository to track all of the work that we will do. It is a common beginning misconception to think of `git` and Github as the same thing. `git` is a commond line tool we will use to track changes to our project. Github is a cloud-based service designed to work with `git` to help us to make sure our work is always backed up on an additional system. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the new repository on Github\n",
    "\n",
    "At github.com, in the upper-right hand corner, click the plus icon and select \"New Repository\". \n",
    "\n",
    "![](doc/img/newrepo.png)\n",
    "\n",
    "Give your new repository a name. It does not need to match `engineering-for-data-science`, but it is generally considered a best practice to make sure the repository on Github and the local directory containing your files have the same name. You do not need to provide a description nor create a `README` file.\n",
    "\n",
    "Finally, click \"Create Repository\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](doc/img/Create_a_New_Repository.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a new directory\n",
    "\n",
    "We use the `mkdir` command to create a new directory to hold our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "bash",
     "local"
    ]
   },
   "outputs": [],
   "source": [
    "mkdir -p engineering-for-data-science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change directories to the new directory\n",
    "\n",
    "Next, use the `cd` (change directory) command to change directories to the new directory we just created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "bash",
     "local"
    ]
   },
   "outputs": [],
   "source": [
    "cd engineering-for-data-science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "bash",
     "local"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized empty Git repository in /home/jovyan/engineering-for-data-science/.git/\n"
     ]
    }
   ],
   "source": [
    "git init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "bash",
     "local"
    ]
   },
   "outputs": [],
   "source": [
    "mkdir chapter-01-introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "bash",
     "local"
    ]
   },
   "outputs": [],
   "source": [
    "echo \".ssh\" > .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "bash",
     "local"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chapter-01-introduction\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "bash",
     "local"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\n",
      "drwxr-xr-x  5 jovyan users 170 Apr 24 23:53 .\n",
      "drwxr-xr-x 20 jovyan users 680 Apr 24 23:51 ..\n",
      "drwxr-xr-x  2 jovyan users  68 Apr 24 23:52 chapter-01-introduction\n",
      "drwxr-xr-x 10 jovyan users 340 Apr 24 23:51 .git\n",
      "-rw-r--r--  1 jovyan users   5 Apr 24 23:53 .gitignore\n"
     ]
    }
   ],
   "source": [
    "ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "bash",
     "local"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Please tell me who you are.\n",
      "\n",
      "Run\n",
      "\n",
      "  git config --global user.email \"you@example.com\"\n",
      "  git config --global user.name \"Your Name\"\n",
      "\n",
      "to set your account's default identity.\n",
      "Omit --global to set the identity only in this repository.\n",
      "\n",
      "fatal: empty ident name (for <jovyan@eb5eb401ee58.(none)>) not allowed\n"
     ]
    }
   ],
   "source": [
    "git add .gitignore && git commit -m 'initialize project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "bash",
     "local"
    ]
   },
   "outputs": [],
   "source": [
    "git config --global user.email \"me@joshuacook.me\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "bash",
     "local"
    ]
   },
   "outputs": [],
   "source": [
    "git config --global user.name \"Joshua Cook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "bash",
     "local"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master (root-commit) 970c61e] initialize project\n",
      " 1 file changed, 1 insertion(+)\n",
      " create mode 100644 .gitignore\n"
     ]
    }
   ],
   "source": [
    "git add .gitignore && git commit -m 'initialize project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "bash",
     "local"
    ]
   },
   "outputs": [],
   "source": [
    "git remote add origin git@github.com:joshuacook/engineering-for-data-science.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "bash",
     "local"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting objects: 3, done.\n",
      "Writing objects: 100% (3/3), 222 bytes | 0 bytes/s, done.\n",
      "Total 3 (delta 0), reused 0 (delta 0)\n",
      "To git@github.com:joshuacook/engineering-for-data-science.git\n",
      " * [new branch]      master -> master\n",
      "Branch master set up to track remote branch master from origin.\n"
     ]
    }
   ],
   "source": [
    "git push -u origin master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](doc/img/joshuacook_engineering-for-data-science.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Git and Github\n",
    "\n",
    "As you work through this text, you will be developing a series of data science projects. Tracking software development work is typically done using version control software. One of the most popular version control tools is `git`. Additonally, it can be useful to use a version control hosting service as a remote backup for work being tracked using `git`. The remote service we will use is Github.com. In my experience, learners who are new to version control often confuse `git` and Github, so it bares repeating -- we will use `git` to track changes we make to our code and Github as a remote backup for these changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring Github\n",
    "\n",
    "We will assume that you have a Github account. Once this has been done, you will need to configue an SSH connection between AWS and Github. This next part may potentially create a confusion. We are actually going to need a new SSH Keypair, this one associated with our AWS instance. This is because it is our AWS instance that will be connecting to Github, not our local machine (See fig. \\ref{fig:ssh_local_remote}).\n",
    "\n",
    "![SSH Connections](doc/img/ch-01-ssh_local_remote.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a New Key Pair\n",
    "\n",
    "In [@lst:create_new_ssh_key_remote], you create a new key pair on your remote AWS instance. In [@lst:ssh_into_new_instance], you connect to your new AWS instance. To do this we will use the IP address we made note of in fig. \\ref{fig:new_ip}. We use SSH to connect to our remote AWS instance. Note that we use the username, `ubuntu`, the default username for the Ubuntu 16 AMI provided by AWS.\n",
    "\n",
    "Listing: Create a new SSH Keypair\n",
    "\n",
    "```{#lst:ssh_into_new_instance}\n",
    "$ ssh ubuntu@54.244.109.176\n",
    "Welcome to Ubuntu 16.04.2 LTS (GNU/Linux 4.4.0-64-generic x86_64)\n",
    "```\n",
    "\n",
    "$\\square$ **Note:** The first time you access your EC2 instance, you should see the following message: `The authenticity of host '54.244.109.176 (54.244.109.176)' can't be established ... Are you sure you want to continue connecting (yes/no)? This is expected. You should hit <ENTER> to accept or type yes and hit <ENTER>.`\n",
    "\n",
    "In [@lst:create_new_ssh_key_remote], you create a new SSH Keypair on our remote AWS instance. Again, during the creation of the SSH Keypair, you will be prompted three times. The first asks where you should save the SSH Keypair, defaulting to the `.ssh/id_rsa` in our home directory. In [@lst:create_new_ssh_key_remote], you see that this is being done at `/home/ubuntu/.ssh/id_rsa`\\footnote{This should be the same for everyone now, as you should be working on an AWS \\texttt{t2.micro} running an Ubuntu system where the user's name is \\texttt{ubuntu}}. The second and third prompts will ask for a passphrase to be added to the key. For our purposes, leaving this passphrase empty will be fine. In other words, the default options are preferable and you may simply hit `<ENTER>` three times.\n",
    "\n",
    "Listing: Create a new SSH Keypair\n",
    "\n",
    "```{#lst:create_new_ssh_key_remote}\n",
    "$ ssh-keygen\n",
    "Generating public/private rsa key pair.\n",
    "Enter file in which to save the key (/home/ubuntu/.ssh/id_rsa):\n",
    "Created directory '/home/ubuntu/.ssh'.\n",
    "Enter passphrase (empty for no passphrase):\n",
    "Enter same passphrase again:\n",
    "Your identification has been saved in /home/ubuntu/.ssh/id_rsa.\n",
    "Your public key has been saved in /home/ubuntu/.ssh/id_rsa.pub.\n",
    "The key fingerprint is:\n",
    "SHA256:ZSpFpgSRgRqlQom8yVBG2dZo1tgkPQdrmUGgMXGDtRY\n",
    "ubuntu@ip-172-31-43-19\n",
    "The key's randomart image is:\n",
    "+---[RSA 2048]----+\n",
    "|o=XBE/*.o        |\n",
    "|==+=O**O.        |\n",
    "|=o++o *o. o      |\n",
    "|o+ . . . +       |\n",
    "|      . S        |\n",
    "|       .         |\n",
    "|                 |\n",
    "|                 |\n",
    "|                 |\n",
    "+----[SHA256]-----+\n",
    "```\n",
    "\n",
    "As before, you can verify the SSH Keypair you just created by displaying the Public Key in your shell ([@lst:cat_pub_key_remote]). Again, you use the `cat` command, which concatenates the contents of `id_rsa.pub` to the shell output.\n",
    "\n",
    "Listing: Display Public SSH Key\n",
    "\n",
    "```{#lst:cat_pub_key_remote}\n",
    "$ cat ~/.ssh/id_rsa.pub\n",
    "ssh-rsa\n",
    "AAAAB3NzaC1yc2EAAAADAQABAAABAQDQ896GUMgCMAIW79gwF3ojRjcUYCKUKc8b+q\n",
    "iQlah2jtr7s0K4WRGjktOy3lCCHO+1UK/GrzY1Y4VxCKoKJDH3G9N5UzyGhlxa/2Ah\n",
    "kKxzHht1knyh/mkVGqYUhuHpXfxUQAstCFrIdp3G0MDPiko2qeJcBF7JSv1lLMbIuM\n",
    "XuVU/Mzq6BU+tEogScYytmLckyEe1j8RJ+e5nBURwmkgj3UAN1DzmU/lVwLlltEpmC\n",
    "DlOel4yEXAw8yBwM3GwjahfiBThvBHpsc43HxWrkM8Yi/kdDnvsDZYxU4zhXZPsPab\n",
    "UY/LfxEod9c6Sui5W8GtAfdi6krnqbzxrKt81Mradh ubuntu@ip-172-31-43-19\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the Public Key to Github\n",
    "\n",
    "Previously, you added your local SSH public key to your AWS account. Now, you will add your AWS SSH public key to your Github account\\footnote{https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/}. First, access the **Settings** for your account by clicking the profile photo in the upper-right corner of any page on Github. Next, in the user settings sidebar, select **SSH and GPG keys**. On the SSH and GPG Keys page, click **New SSH key**. On the next page, give your key a descriptive title e.g. \"AWS Feb 2018\" and then paste your AWS public key in to the \"Key\" field . Finally, click **Add SSH key** and confirm your Github password , if prompted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning to read the Bash Prompt\n",
    "\n",
    "During your work you will no doubt notice that an idle SSH connection may become disconnected and/or unresponsive. Should this happen, simply close the terminal session, launch a new one, and reconnect to the remote instance. \n",
    "\n",
    "The most important thing is that you are aware of which system your current shell session is connected to. Shell prompts are designed to relay this information to you immediately. If you are new to working with Bash, you may need to train yourself to being aware of the prompt when typing. [@lst:default_AWS_prompt] shows the default AWS Bash prompt. The information contained is the username, `ubuntu`, and the private IP address of the AWS instance. **This is not the public address you use to connect**. What is useful about this, is that we can immediately see that the user is `ubuntu`. This tells us we are connected to AWS.\n",
    "\n",
    "Listing: The default AWS Bash prompt\n",
    "```{#lst:default_AWS_prompt}\n",
    "ubuntu@ip-172-31-21-89:~$\n",
    "```\n",
    "\n",
    "Your local system will no doubt display something different (See [@lst:other_prompt]). Again, the important thing is to take note of what is displayed by the prompt and to learn to associate that prompt with the correct system. As you become a more advanced Bash user, you may wish to personalize your prompt, but for now it is imperative that you learn to read the prompt in order to always know to which system you are connected.\n",
    "\n",
    "Listing: A local Bash prompt\n",
    "```{#lst:other_prompt}\n",
    "joshuas-macbook-pro:~$\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test your SSH Connection to Github\n",
    "\n",
    "Having added you AWS Public Key to your Github account, you should verify your SSH connection from your AWS instance. In [@lst:verify_github_ssh], we attempt to connect to Github via SSH. As before, we receive a message about the authenticity of the connection. Again, type `yes`, and continue. If successful, you will see a message telling you have successfully authenticated but that Github does not provide shell access.\n",
    "\n",
    "Listing: Verify Github SSH Key\n",
    "```{#lst:verify_github_ssh}\n",
    "ubuntu@ip-172-31-21-89:~$ ssh -T git@github.com\n",
    "The authenticity of host 'github.com (IP ADDRESS)' can't be\n",
    "established.\n",
    "RSA key fingerprint is\n",
    "16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.\n",
    "Are you sure you want to continue connecting (yes/no)? yes\n",
    "Hi username! You've successfully authenticated, but GitHub does\n",
    "not provide shell access.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker \\& Docker Compose\n",
    "\n",
    "Having configured our SSH connections and provisioned a new AWS EC2 instance, it is time to get to the business of building your data science platform. To do this you will use the containerization platform Docker and its Docker Compose tool. While Docker is very easy to use, it can be difficult to understand for the uninitiated. In an earlier work, *Docker for Data Science*\\footnote{https://www.apress.com/us/book/9781484230114}, I wrote:\n",
    "\n",
    "> [Using Docker] we add a layer of complexity to our software, but in doing so gain the advantage of ensuring that our local development environment will be identical to any possible environment into which we would deploy the application.\n",
    "\n",
    "It may be simpler, however, to simply think about using Docker as a way to manage a running process. Your system will be running two processes: an IPython shell and a PostgreSQL server. Were you to not use Docker, you would need to ensure that the AWS instance had all of the libraries required to run both of those processes (and keep those libraries up to date).\n",
    "\n",
    "Instead, you will let Docker manage the processes using a container for each process. Each respective container will be run using a predefined image built using best practices and ready to run their respective process. The exchange is this: you will take on the congitive burden of *understanding* what Docker is doing and Docker (and the Docker community) will take over the burden of making sure that your processes run.\n",
    "\n",
    "### Docker Compose\n",
    "\n",
    "Docker Compose is a tool built for managing an application consisting of multiple containers. Using Docker Compose, it is possible to completely define an application using a simple text file. To make this conversation less abstract, let's have a look at the `docker-compose.yml` file you will use to define your first application (See [@lst:docker_compose]).\n",
    "\n",
    "Listing: Your Data Science Application\n",
    "\n",
    "```{#lst:docker_compose}\n",
    "version: \"3\"\n",
    "services:\n",
    "  ipython_shell:\n",
    "    image: jupyter/scipy-notebook\n",
    "  database:\n",
    "    image: postgres\n",
    "    volumes:\n",
    "      - postgres_data:/var/lib/postgresql/data\n",
    "volumes:\n",
    "  postgres_data\n",
    "```\n",
    "\n",
    "That's it. This simple file completely defines a fully-functioning Data Science Application. In it, we define the two services we need: `ipython_shell` and `database`. These two services are defined using the `jupyter/scipy-notebook` and `postgres` images. When we launch the application, the images will be pulled from Docker Hub into our local memory and then launched. The one other thing we do is create a data volume `postgres_data`. We will use this as the data volume for our database server so that if for some reason we have to shut our system down, we do not lose our data. The data will exist on this volume independent of the services.\n",
    "\n",
    "$\\square$ **Note:** Throughout this text, when discussing infrastructure, I may casually refer to containers, services, and processes. At the risk of annoying your local site reliability engineer, you may treat these as terms as synonomous. Care should be taken, however, not to confuse services/containers/processes and images. An image defines a service, but a service should be thought of as a living and active thing. You may loosely compare the service-image relationship to the object-class relationship in Object-Oriented Programming. A service is a running container defined by an image, just like an object is an instance of a class that exists in memory.\n",
    "\n",
    "### Installing and Configuring Docker\n",
    "\n",
    "Installing Docker on your AWS instance is a downright trivial process. It consists of running an install script that can be obtained from Docker and then adding your user to the Docker group. In [@lst:install_docker], we run these two commands. First, we download the install script from https://get.docker.com, then immediately pipe the script into the shell (`| sh`).\n",
    "\n",
    "$\\square$ **Note:** It is generally considered to be a significant security vulnerability to execute arbitrary code obtained from an unknown, or untrusted source. For our purposes, the source (https://get.docker/com) is considered trustworthy, we are using SSL to perform the curl, and in practice this is the method I use to install Docker. Still, it may make the security minded more comfortable to `curl` the script, inspect, and then run it.\n",
    "\n",
    "Listing: Install Docker via a Shell Script\n",
    "\n",
    "```{#lst:install_docker}\n",
    "$ curl -sSL https://get.docker.com/ | sh\n",
    "# Executing docker install script, commit: 1d31602\n",
    "+ sudo -E sh -c apt-get update -qq >/dev/null\n",
    "...\n",
    "\n",
    "Client:\n",
    " Version:   18.02.0-ce\n",
    " API version:   1.36\n",
    " Go version:    go1.9.3\n",
    " Git commit:    fc4de44\n",
    " Built: Wed Feb  7 21:16:33 2018\n",
    " OS/Arch:   linux/amd64\n",
    " Experimental:  false\n",
    " Orchestrator:  swarm\n",
    "\n",
    "Server:\n",
    " Engine:\n",
    "  Version:  18.02.0-ce\n",
    "  API version:  1.36 (minimum version 1.12)\n",
    "  Go version:   go1.9.3\n",
    "  Git commit:   fc4de44\n",
    "  Built:    Wed Feb  7 21:15:05 2018\n",
    "  OS/Arch:  linux/amd64\n",
    "  Experimental: false\n",
    "\n",
    "...\n",
    "\n",
    "```\n",
    "\n",
    "When the script completes there is one last thing to be done. In [@lst:add_to_docker_group], you add the `ubuntu` user to the `docker` group. By default, the command line docker client will require sudo access in order to issue commands to the docker daemon. You can add the `ubuntu` user to the `docker` group in order to allow the `ubuntu` user to issue commands to docker without sudo.\n",
    "\n",
    "Listing: Add the Ubuntu User to the Docker Group\n",
    "\n",
    "```{#lst:add_to_docker_group}\n",
    "$ sudo usermod -aG docker ubuntu\n",
    "```\n",
    "\n",
    "Finally, in order to force the changes to take effect, you should disconnect and reconnect to their remote system. You can achieve this by typing `exit` or `ctrl-d` and then reconnecting via ssh to your EC2 instance.\n",
    "\n",
    "### Installing and Configuring Docker\n",
    "\n",
    "Recall that regardless of your local operating system, you are working on an AWS EC2 Instance running the Linux variant, Ubuntu. As such, `docker-compose`can be installed using the instructions provided here: https://github.com/docker/compose/releases, which are written specifically for Linux machines. As of the writing of this book, this consists of two steps.\n",
    "\n",
    "In [@lst:curl_docker_compose], you use `curl` to retrieve the `docker-compose` binary from Github. As of the writing of this book. the latest version of `docker-compose` was `1.19.0`. You should retrieve the latest version from the above url.\n",
    "\n",
    "Listing: Retrieve `docker-compose` binary from Github\n",
    "\n",
    "```{#lst:curl_docker_compose}\n",
    "$ sudo curl -L https://github.com/docker/compose/releases/download/1.19.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose\n",
    "```\n",
    "\n",
    "In [@lst:chmod_docker-compose], we use the `chmod`\\footnote{The unix \"change mode\" utility. I pronounce it \"shmod\".} utility to allow `docker-compose` to be executed (`+x`).\n",
    "\n",
    "Listing: Enable Docker Compose to be Executed\n",
    "\n",
    "```{#lst:chmod_docker-compose}\n",
    "$ sudo chmod +x /usr/local/bin/docker-compose\n",
    "```\n",
    "\n",
    "Finally, in [@lst:docker_compose_version], we check the version of `docker-compose` against what we expect to have installed.\n",
    "\n",
    "```{#lst:docker_compose_version}\n",
    "$ docker-compose -v\n",
    "docker-compose version 1.19.0, build 9e633ef\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "1. What went wrong here? What should you do?\n",
    "\n",
    "    ```\n",
    "    failed to register layer: Error processing tar file(exit status 1):\n",
    "    write / usr/bin/python2.7: no space left on device\n",
    "    ```\n",
    "\n",
    "1. What went wrong here? What should you do?\n",
    "\n",
    "    ```\n",
    "    docker: Error response from daemon: driver failed programming external\n",
    "    connectivity on endpoint cocky_swartz (08124b75d2f031def6d36c6bc819549c009\n",
    "    391e3bd76f3fe3b4e06e11be6fbad): Bind for 0.0.0.0:80 failed: port is\n",
    "    already allocated.\n",
    "    ```\n",
    "\n",
    "1. What doe this command do?\n",
    "\n",
    "    ```\n",
    "    curl -sSL https://get.docker.com | sh\n",
    "    ```\n",
    "\n",
    "1. What are two ways to display the contents of a text file from the command line?\n",
    "2. What are the two modes in vim?\n",
    "3. How do you save the changes in a file in vim?\n",
    "1. How would you find all files in your current directory that contain the string “bash”?\n",
    "1. What are the steps to launching a Jupyter Notebook Server on a running AWS instance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_metadata": {
   "title": "Engineering For Data Science with Docker"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
